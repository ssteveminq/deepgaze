!_TAG_FILE_FORMAT	2	/extended format; --format=1 will not append ;" to lines/
!_TAG_FILE_SORTED	1	/0=unsorted, 1=sorted, 2=foldcase/
!_TAG_PROGRAM_AUTHOR	Darren Hiebert	/dhiebert@users.sourceforge.net/
!_TAG_PROGRAM_NAME	Exuberant Ctags	//
!_TAG_PROGRAM_URL	http://ctags.sourceforge.net	/official site/
!_TAG_PROGRAM_VERSION	5.9~svn20110310	//
ALL_POINTS	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^ALL_POINTS = list(range(0,68)) #Used for debug only$/;"	v
ALL_POINTS	examples/ex_pnp_head_pose_estimation_video.py	/^ALL_POINTS = list(range(0,68)) #Used for debug only$/;"	v
ALL_POINTS	examples/ex_pnp_head_pose_estimation_webcam.py	/^ALL_POINTS = list(range(0,68)) #Used for debug only$/;"	v
BackProjectionColorDetector	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^class BackProjectionColorDetector:$/;"	c
BackProjectionColorDetector	deepgaze/color_detection.py	/^class BackProjectionColorDetector:$/;"	c
BinaryMaskAnalyser	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^class BinaryMaskAnalyser:$/;"	c
BinaryMaskAnalyser	deepgaze/mask_analysis.py	/^class BinaryMaskAnalyser:$/;"	c
CnnHeadPoseEstimator	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^class CnnHeadPoseEstimator:$/;"	c
CnnHeadPoseEstimator	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^class CnnHeadPoseEstimator:$/;"	c
CnnHeadPoseEstimator	deepgaze/cnn_head_pose_estimator.py	/^class CnnHeadPoseEstimator:$/;"	c
CnnHeadPoseEstimator	deepgaze/head_pose_estimation.py	/^class CnnHeadPoseEstimator:$/;"	c
DEBUG	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^DEBUG = False$/;"	v
DEBUG	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^DEBUG = False$/;"	v
DEBUG	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^DEBUG = False$/;"	v
DEBUG	deepgaze/cnn_head_pose_estimator.py	/^DEBUG = False$/;"	v
DEBUG	deepgaze/head_pose_estimation.py	/^DEBUG = False$/;"	v
DEBUG	deepgaze/saliency_map.py	/^DEBUG = False$/;"	v
DEBUG	examples/ex_cnn_cascade_training_face_detection/nms.py	/^DEBUG = True$/;"	v
DEBUG	examples/ex_pnp_head_pose_estimation_video.py	/^DEBUG = True $/;"	v
DEBUG	examples/ex_pnp_head_pose_estimation_webcam.py	/^DEBUG = True $/;"	v
DiffMotionDetector	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^class DiffMotionDetector:$/;"	c
DiffMotionDetector	deepgaze/motion_detection.py	/^class DiffMotionDetector:$/;"	c
DiscreteBayesFilter	build/lib.linux-x86_64-2.7/deepgaze/bayes_filter.py	/^class DiscreteBayesFilter:$/;"	c
DiscreteBayesFilter	deepgaze/bayes_filter.py	/^class DiscreteBayesFilter:$/;"	c
ENABLE_CAPTURE	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^            ENABLE_CAPTURE=False$/;"	v
ENABLE_CAPTURE	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^            ENABLE_CAPTURE=True$/;"	v
ENABLE_CAPTURE	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^ENABLE_CAPTURE = False$/;"	v
FasaSaliencyMapping	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^class FasaSaliencyMapping:$/;"	c
FasaSaliencyMapping	deepgaze/saliency_map.py	/^class FasaSaliencyMapping:$/;"	c
HaarFaceDetector	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^class HaarFaceDetector:$/;"	c
HaarFaceDetector	deepgaze/face_detection.py	/^class HaarFaceDetector:$/;"	c
HistogramColorClassifier	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^class HistogramColorClassifier:$/;"	c
HistogramColorClassifier	deepgaze/color_classification.py	/^class HistogramColorClassifier:$/;"	c
IOU	examples/ex_cnn_cascade_training_face_detection/iou.py	/^def IOU(box1, box2):$/;"	f
IS_DLIB_INSTALLED	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    IS_DLIB_INSTALLED = False$/;"	v
IS_DLIB_INSTALLED	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    IS_DLIB_INSTALLED = True$/;"	v
IS_DLIB_INSTALLED	deepgaze/head_pose_estimation.py	/^    IS_DLIB_INSTALLED = False$/;"	v
IS_DLIB_INSTALLED	deepgaze/head_pose_estimation.py	/^    IS_DLIB_INSTALLED = True$/;"	v
LEFT_EYE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^LEFT_EYE = 45$/;"	v
LEFT_EYE	deepgaze/face_landmark_detection.py	/^LEFT_EYE = 45$/;"	v
LEFT_SIDE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^LEFT_SIDE = 16$/;"	v
LEFT_SIDE	deepgaze/face_landmark_detection.py	/^LEFT_SIDE = 16$/;"	v
LEFT_TEAR	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^LEFT_TEAR = 42$/;"	v
LEFT_TEAR	deepgaze/face_landmark_detection.py	/^LEFT_TEAR = 42$/;"	v
MENTON	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^MENTON = 8$/;"	v
MENTON	deepgaze/face_landmark_detection.py	/^MENTON = 8$/;"	v
Mog2MotionDetector	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^class Mog2MotionDetector:$/;"	c
Mog2MotionDetector	deepgaze/motion_detection.py	/^class Mog2MotionDetector:$/;"	c
MogMotionDetector	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^class MogMotionDetector:$/;"	c
MogMotionDetector	deepgaze/motion_detection.py	/^class MogMotionDetector:$/;"	c
MultiBackProjectionColorDetector	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^class MultiBackProjectionColorDetector:$/;"	c
MultiBackProjectionColorDetector	deepgaze/color_detection.py	/^class MultiBackProjectionColorDetector:$/;"	c
NMS	examples/ex_cnn_cascade_training_face_detection/nms.py	/^def NMS(data, thresh=0.8):$/;"	f
NOSE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^NOSE = 30$/;"	v
NOSE	deepgaze/face_landmark_detection.py	/^NOSE = 30$/;"	v
P3D_FRONTAL_BREADTH_LEFT	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_FRONTAL_BREADTH_LEFT = numpy.float32([-20.0, 56.1, 10.0]) #26$/;"	v
P3D_FRONTAL_BREADTH_LEFT	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_FRONTAL_BREADTH_LEFT = numpy.float32([-20.0, 56.1, 10.0]) #26$/;"	v
P3D_FRONTAL_BREADTH_LEFT	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_FRONTAL_BREADTH_LEFT = numpy.float32([-20.0, 56.1, 10.0]) #26$/;"	v
P3D_FRONTAL_BREADTH_RIGHT	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_FRONTAL_BREADTH_RIGHT = numpy.float32([-20.0, -56.1, 10.0]) #17$/;"	v
P3D_FRONTAL_BREADTH_RIGHT	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_FRONTAL_BREADTH_RIGHT = numpy.float32([-20.0, -56.1, 10.0]) #17$/;"	v
P3D_FRONTAL_BREADTH_RIGHT	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_FRONTAL_BREADTH_RIGHT = numpy.float32([-20.0, -56.1, 10.0]) #17$/;"	v
P3D_GONION_LEFT	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_GONION_LEFT = numpy.float32([-110.0, 77.5, -85.0]) #12$/;"	v
P3D_GONION_LEFT	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_GONION_LEFT = numpy.float32([-110.0, 77.5, -85.0]) #12$/;"	v
P3D_GONION_LEFT	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_GONION_LEFT = numpy.float32([-110.0, 77.5, -85.0]) #12$/;"	v
P3D_GONION_RIGHT	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_GONION_RIGHT = numpy.float32([-110.0, -77.5, -85.0]) #4$/;"	v
P3D_GONION_RIGHT	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_GONION_RIGHT = numpy.float32([-110.0, -77.5, -85.0]) #4$/;"	v
P3D_GONION_RIGHT	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_GONION_RIGHT = numpy.float32([-110.0, -77.5, -85.0]) #4$/;"	v
P3D_LEFT_EYE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_LEFT_EYE = numpy.float32([-20.0, 65.5,-5.0]) #45$/;"	v
P3D_LEFT_EYE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_LEFT_EYE = numpy.float32([-20.0, 65.5,-5.0]) #45$/;"	v
P3D_LEFT_EYE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_LEFT_EYE = numpy.float32([-20.0, 65.5,-5.0]) #45$/;"	v
P3D_LEFT_SIDE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_LEFT_SIDE = numpy.float32([-100.0, 77.5, -5.0]) #16$/;"	v
P3D_LEFT_SIDE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_LEFT_SIDE = numpy.float32([-100.0, 77.5, -5.0]) #16$/;"	v
P3D_LEFT_SIDE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_LEFT_SIDE = numpy.float32([-100.0, 77.5, -5.0]) #16$/;"	v
P3D_LEFT_TEAR	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_LEFT_TEAR = numpy.float32([-10.0, 40.5,-5.0]) #42$/;"	v
P3D_LEFT_TEAR	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_LEFT_TEAR = numpy.float32([-10.0, 40.5,-5.0]) #42$/;"	v
P3D_LEFT_TEAR	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_LEFT_TEAR = numpy.float32([-10.0, 40.5,-5.0]) #42$/;"	v
P3D_MENTON	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_MENTON = numpy.float32([0.0, 0.0, -122.7]) #8$/;"	v
P3D_MENTON	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_MENTON = numpy.float32([0.0, 0.0, -122.7]) #8$/;"	v
P3D_MENTON	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_MENTON = numpy.float32([0.0, 0.0, -122.7]) #8$/;"	v
P3D_NOSE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_NOSE = numpy.float32([21.1, 0.0, -48.0]) #30$/;"	v
P3D_NOSE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_NOSE = numpy.float32([21.1, 0.0, -48.0]) #30$/;"	v
P3D_NOSE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_NOSE = numpy.float32([21.1, 0.0, -48.0]) #30$/;"	v
P3D_RIGHT_EYE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_EYE = numpy.float32([-20.0, -65.5,-5.0]) #36$/;"	v
P3D_RIGHT_EYE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_EYE = numpy.float32([-20.0, -65.5,-5.0]) #36$/;"	v
P3D_RIGHT_EYE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_RIGHT_EYE = numpy.float32([-20.0, -65.5,-5.0]) #36$/;"	v
P3D_RIGHT_SIDE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_SIDE = numpy.float32([-100.0, -77.5, -5.0]) #0$/;"	v
P3D_RIGHT_SIDE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_SIDE = numpy.float32([-100.0, -77.5, -5.0]) #0$/;"	v
P3D_RIGHT_SIDE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_RIGHT_SIDE = numpy.float32([-100.0, -77.5, -5.0]) #0$/;"	v
P3D_RIGHT_TEAR	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_TEAR = numpy.float32([-10.0, -40.5,-5.0]) #39$/;"	v
P3D_RIGHT_TEAR	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_RIGHT_TEAR = numpy.float32([-10.0, -40.5,-5.0]) #39$/;"	v
P3D_RIGHT_TEAR	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_RIGHT_TEAR = numpy.float32([-10.0, -40.5,-5.0]) #39$/;"	v
P3D_SELLION	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_SELLION = numpy.float32([0.0, 0.0, 0.0]) #27$/;"	v
P3D_SELLION	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_SELLION = numpy.float32([0.0, 0.0, 0.0]) #27$/;"	v
P3D_SELLION	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_SELLION = numpy.float32([0.0, 0.0, 0.0]) #27$/;"	v
P3D_STOMION	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_STOMION = numpy.float32([10.0, 0.0, -75.0]) #62$/;"	v
P3D_STOMION	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_STOMION = numpy.float32([10.0, 0.0, -75.0]) #62$/;"	v
P3D_STOMION	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_STOMION = numpy.float32([10.0, 0.0, -75.0]) #62$/;"	v
P3D_SUB_NOSE	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^P3D_SUB_NOSE = numpy.float32([5.0, 0.0, -52.0]) #33$/;"	v
P3D_SUB_NOSE	examples/ex_pnp_head_pose_estimation_video.py	/^P3D_SUB_NOSE = numpy.float32([5.0, 0.0, -52.0]) #33$/;"	v
P3D_SUB_NOSE	examples/ex_pnp_head_pose_estimation_webcam.py	/^P3D_SUB_NOSE = numpy.float32([5.0, 0.0, -52.0]) #33$/;"	v
PRINT_TIME	examples/ex_fasa_saliency_map/ex_fasa_saliency_map_webcam.py	/^PRINT_TIME = False$/;"	v
ParticleFilter	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^class ParticleFilter:$/;"	c
ParticleFilter	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^class ParticleFilter:$/;"	c
ParticleFilter	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^class ParticleFilter:$/;"	c
ParticleFilter	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^class ParticleFilter:$/;"	c
ParticleFilter	deepgaze/motion_tracking.py	/^class ParticleFilter:$/;"	c
ParticleFilter	deepgaze/object3d_tracking.py	/^class ParticleFilter:$/;"	c
PnpHeadPoseEstimator	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^class PnpHeadPoseEstimator:$/;"	c
PnpHeadPoseEstimator	deepgaze/head_pose_estimation.py	/^class PnpHeadPoseEstimator:$/;"	c
RESOLUTION_HEIGHT	examples/ex_fasa_saliency_map/ex_fasa_saliency_map_webcam.py	/^RESOLUTION_HEIGHT = 180$/;"	v
RESOLUTION_WIDTH	examples/ex_fasa_saliency_map/ex_fasa_saliency_map_webcam.py	/^RESOLUTION_WIDTH = 320$/;"	v
RIGHT_EYE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^RIGHT_EYE = 36$/;"	v
RIGHT_EYE	deepgaze/face_landmark_detection.py	/^RIGHT_EYE = 36$/;"	v
RIGHT_SIDE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^RIGHT_SIDE = 0$/;"	v
RIGHT_SIDE	deepgaze/face_landmark_detection.py	/^RIGHT_SIDE = 0$/;"	v
RIGHT_TEAR	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^RIGHT_TEAR = 39$/;"	v
RIGHT_TEAR	deepgaze/face_landmark_detection.py	/^RIGHT_TEAR = 39$/;"	v
RangeColorDetector	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^class RangeColorDetector:$/;"	c
RangeColorDetector	deepgaze/color_detection.py	/^class RangeColorDetector:$/;"	c
SELLION	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^SELLION = 27$/;"	v
SELLION	deepgaze/face_landmark_detection.py	/^SELLION = 27$/;"	v
STOMION	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^STOMION = 62$/;"	v
STOMION	deepgaze/face_landmark_detection.py	/^STOMION = 62$/;"	v
SUB_NOSE	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^SUB_NOSE = 33$/;"	v
SUB_NOSE	deepgaze/face_landmark_detection.py	/^SUB_NOSE = 33$/;"	v
TRACKED_POINTS	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^TRACKED_POINTS = (0, 4, 8, 12, 16, 17, 26, 27, 30, 33, 36, 39, 42, 45, 62)$/;"	v
TRACKED_POINTS	examples/ex_pnp_head_pose_estimation_video.py	/^TRACKED_POINTS = (0, 4, 8, 12, 16, 17, 26, 27, 30, 33, 36, 39, 42, 45, 62)$/;"	v
TRACKED_POINTS	examples/ex_pnp_head_pose_estimation_webcam.py	/^TRACKED_POINTS = (0, 4, 8, 12, 16, 17, 26, 27, 30, 33, 36, 39, 42, 45, 62)$/;"	v
USE_WEBCAM	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^USE_WEBCAM = False$/;"	v
__init__	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	build/lib.linux-x86_64-2.7/deepgaze/bayes_filter.py	/^    def __init__(self, states_number):$/;"	m	class:DiscreteBayesFilter
__init__	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^    def __init__(self, YawFilePath, PitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
__init__	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def __init__(self, channels=[0, 1, 2], hist_size=[10, 10, 10], hist_range=[0, 256, 0, 256, 0, 256], hist_type='BGR'):$/;"	m	class:HistogramColorClassifier
__init__	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def __init__(self):$/;"	m	class:BackProjectionColorDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def __init__(self):$/;"	m	class:MultiBackProjectionColorDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def __init__(self, min_range, max_range):$/;"	m	class:RangeColorDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def __init__(self, frontalFacePath, profileFacePath):$/;"	m	class:HaarFaceDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^    def __init__(self, landmarkPath):$/;"	m	class:faceLandmarkDetection
__init__	build/lib.linux-x86_64-2.7/deepgaze/haar_cascade.py	/^    def __init__(self, frontalFacePath, profileFacePath):$/;"	m	class:haarCascade
__init__	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def __init__(self, cam_w, cam_h, dlib_shape_predictor_file_path):$/;"	m	class:PnpHeadPoseEstimator
__init__	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def __init__(self, tf_session):$/;"	m	class:CnnHeadPoseEstimator
__init__	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def __init__(self):$/;"	m	class:DiffMotionDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def __init__(self):$/;"	m	class:Mog2MotionDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def __init__(self, history=10, numberMixtures=3, backgroundRatio=0.6, noise=20):$/;"	m	class:MogMotionDetector
__init__	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def __init__(self, image_h, image_w):$/;"	m	class:FasaSaliencyMapping
__init__	deepgaze/bayes_filter.py	/^    def __init__(self, states_number):$/;"	m	class:DiscreteBayesFilter
__init__	deepgaze/cnn_head_pose_estimator.py	/^    def __init__(self, YawFilePath, PitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
__init__	deepgaze/color_classification.py	/^    def __init__(self, channels=[0, 1, 2], hist_size=[10, 10, 10], hist_range=[0, 256, 0, 256, 0, 256], hist_type='BGR'):$/;"	m	class:HistogramColorClassifier
__init__	deepgaze/color_detection.py	/^    def __init__(self):$/;"	m	class:BackProjectionColorDetector
__init__	deepgaze/color_detection.py	/^    def __init__(self):$/;"	m	class:MultiBackProjectionColorDetector
__init__	deepgaze/color_detection.py	/^    def __init__(self, min_range, max_range):$/;"	m	class:RangeColorDetector
__init__	deepgaze/face_detection.py	/^    def __init__(self, frontalFacePath, profileFacePath):$/;"	m	class:HaarFaceDetector
__init__	deepgaze/face_landmark_detection.py	/^    def __init__(self, landmarkPath):$/;"	m	class:faceLandmarkDetection
__init__	deepgaze/haar_cascade.py	/^    def __init__(self, frontalFacePath, profileFacePath):$/;"	m	class:haarCascade
__init__	deepgaze/head_pose_estimation.py	/^    def __init__(self, cam_w, cam_h, dlib_shape_predictor_file_path):$/;"	m	class:PnpHeadPoseEstimator
__init__	deepgaze/head_pose_estimation.py	/^    def __init__(self, tf_session):$/;"	m	class:CnnHeadPoseEstimator
__init__	deepgaze/motion_detection.py	/^    def __init__(self):$/;"	m	class:DiffMotionDetector
__init__	deepgaze/motion_detection.py	/^    def __init__(self):$/;"	m	class:Mog2MotionDetector
__init__	deepgaze/motion_detection.py	/^    def __init__(self, history=10, numberMixtures=3, backgroundRatio=0.6, noise=20):$/;"	m	class:MogMotionDetector
__init__	deepgaze/motion_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	deepgaze/object3d_tracking.py	/^    def __init__(self, width, height, N):$/;"	m	class:ParticleFilter
__init__	deepgaze/saliency_map.py	/^    def __init__(self, image_h, image_w):$/;"	m	class:FasaSaliencyMapping
_allocate_pitch_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def _allocate_pitch_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_allocate_pitch_variables	deepgaze/head_pose_estimation.py	/^    def _allocate_pitch_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_allocate_roll_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def _allocate_roll_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_allocate_roll_variables	deepgaze/head_pose_estimation.py	/^    def _allocate_roll_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_allocate_yaw_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def _allocate_yaw_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_allocate_yaw_variables	deepgaze/head_pose_estimation.py	/^    def _allocate_yaw_variables(self):$/;"	m	class:CnnHeadPoseEstimator
_bilateral_filtering	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def _bilateral_filtering(self):$/;"	m	class:FasaSaliencyMapping
_bilateral_filtering	deepgaze/saliency_map.py	/^    def _bilateral_filtering(self):$/;"	m	class:FasaSaliencyMapping
_calculate_histogram	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def _calculate_histogram(self, image, tot_bins=8):$/;"	m	class:FasaSaliencyMapping
_calculate_histogram	deepgaze/saliency_map.py	/^    def _calculate_histogram(self, image, tot_bins=8):$/;"	m	class:FasaSaliencyMapping
_calculate_probability	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def _calculate_probability(self):$/;"	m	class:FasaSaliencyMapping
_calculate_probability	deepgaze/saliency_map.py	/^    def _calculate_probability(self):$/;"	m	class:FasaSaliencyMapping
_compute_saliency_map	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def _compute_saliency_map(self):$/;"	m	class:FasaSaliencyMapping
_compute_saliency_map	deepgaze/saliency_map.py	/^    def _compute_saliency_map(self):$/;"	m	class:FasaSaliencyMapping
_findFrontalFace	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def _findFrontalFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findFrontalFace	build/lib.linux-x86_64-2.7/deepgaze/haar_cascade.py	/^    def _findFrontalFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:haarCascade
_findFrontalFace	deepgaze/face_detection.py	/^    def _findFrontalFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findFrontalFace	deepgaze/haar_cascade.py	/^    def _findFrontalFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:haarCascade
_findMultipleFrontalFaces	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def _findMultipleFrontalFaces(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findMultipleFrontalFaces	deepgaze/face_detection.py	/^    def _findMultipleFrontalFaces(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findMultipleProfileFaces	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def _findMultipleProfileFaces(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findMultipleProfileFaces	deepgaze/face_detection.py	/^    def _findMultipleProfileFaces(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findProfileFace	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def _findProfileFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findProfileFace	build/lib.linux-x86_64-2.7/deepgaze/haar_cascade.py	/^    def _findProfileFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:haarCascade
_findProfileFace	deepgaze/face_detection.py	/^    def _findProfileFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:HaarFaceDetector
_findProfileFace	deepgaze/haar_cascade.py	/^    def _findProfileFace(self, inputImg, scaleFactor=1.1, minSizeX=30, minSizeY=30, minNeighbors=4):$/;"	m	class:haarCascade
_init_pitch_	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^    def _init_pitch_(self, PitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
_init_pitch_	deepgaze/cnn_head_pose_estimator.py	/^    def _init_pitch_(self, PitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
_init_yaw_	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^    def _init_yaw_(self, YawFilePath):$/;"	m	class:CnnHeadPoseEstimator
_init_yaw_	deepgaze/cnn_head_pose_estimator.py	/^    def _init_yaw_(self, YawFilePath):$/;"	m	class:CnnHeadPoseEstimator
_precompute_parameters	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def _precompute_parameters(self, sigmac=16):$/;"	m	class:FasaSaliencyMapping
_precompute_parameters	deepgaze/saliency_map.py	/^    def _precompute_parameters(self, sigmac=16):$/;"	m	class:FasaSaliencyMapping
_return_landmarks	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def _return_landmarks(self, inputImg, roiX, roiY, roiW, roiH, points_to_return=range(0,68)):$/;"	m	class:PnpHeadPoseEstimator
_return_landmarks	deepgaze/head_pose_estimation.py	/^    def _return_landmarks(self, inputImg, roiX, roiY, roiW, roiH, points_to_return=range(0,68)):$/;"	m	class:PnpHeadPoseEstimator
_sess	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^_sess = tf.Session()$/;"	v
accuracy	examples/ex_cnn_cascade_training_face_detection/24net_calibration_training.py	/^def accuracy(predictions, labels, verbose=False):$/;"	f
accuracy	examples/ex_cnn_cascade_training_face_detection/24net_detection_training.py	/^def accuracy(predictions, labels, verbose=False):$/;"	f
accuracy	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^def accuracy(predictions, labels, verbose=False):$/;"	f
addModelHistogram	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def addModelHistogram(self, model_frame, name=''):$/;"	m	class:HistogramColorClassifier
addModelHistogram	deepgaze/color_classification.py	/^    def addModelHistogram(self, model_frame, name=''):$/;"	m	class:HistogramColorClassifier
allTheFaces	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^allTheFaces = hfd.returnMultipleFacesPosition(image, runFrontal=True, runFrontalRotated=True, $/;"	v
all_vars	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^all_vars = tf.all_variables()$/;"	v
area	examples/ex_cnn_cascade_training_face_detection/iou.py	/^def area(box):$/;"	f
area	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^        area = w_rect * h_rect$/;"	v
author	setup.py	/^  author='Massimiliano Patacchiola',$/;"	v
axis	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    axis = np.float32([[0.0, 0.0, 0.0], $/;"	v
background_image	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^background_image = cv2.imread(".\/background.png")$/;"	v
background_image	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^background_image = cv2.imread(".\/background.png")$/;"	v
batch_data	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    batch_data = training_dataset[offset:(offset + batch_size), :]$/;"	v
batch_labels	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    batch_labels = training_label[offset:(offset + batch_size), :]$/;"	v
batch_size	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^batch_size = 128 #was 128$/;"	v
belief	examples/ex_bayes_filter.py	/^    belief = belief_updated$/;"	v
belief	examples/ex_bayes_filter.py	/^belief = np.array([0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2], dtype=np.float32)$/;"	v
belief	examples/ex_bayes_filter.py	/^belief = np.array([1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=np.float32)$/;"	v
belief_predicted	examples/ex_bayes_filter.py	/^    belief_predicted = my_filter.predict(belief, cpt_motion_model)$/;"	v
belief_updated	examples/ex_bayes_filter.py	/^    belief_updated = my_filter.update(belief_predicted, 1, cpt_measurement_accuracy)$/;"	v
belief_updated	examples/ex_bayes_filter.py	/^    belief_updated = my_filter.update(belief_predicted, 2, cpt_measurement_accuracy)$/;"	v
belief_updated	examples/ex_bayes_filter.py	/^    belief_updated = my_filter.update(belief_predicted, 3, cpt_measurement_accuracy)$/;"	v
belief_updated	examples/ex_bayes_filter.py	/^    belief_updated = my_filter.update(belief_predicted, 4, cpt_measurement_accuracy)$/;"	v
beta	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    beta = 5e-4$/;"	v
biases_hidden1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    biases_hidden1 = tf.Variable(tf.zeros([num_hidden_units_2]))    $/;"	v
biases_hidden1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    biases_hidden1 = tf.Variable(tf.zeros([num_hidden_units_2]))    $/;"	v
biases_hidden2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    biases_hidden2 = tf.Variable(tf.zeros([num_hidden_units_3]))$/;"	v
biases_hidden2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    biases_hidden2 = tf.Variable(tf.zeros([num_hidden_units_3]))$/;"	v
biases_input0	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    biases_input0 = tf.Variable(tf.zeros([num_hidden_units_1]))$/;"	v
biases_input0	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    biases_input0 = tf.Variable(tf.zeros([num_hidden_units_1]))$/;"	v
biases_output3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    biases_output3 = tf.Variable(tf.zeros([num_labels]))$/;"	v
biases_output3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    biases_output3 = tf.Variable(tf.zeros([num_labels]))$/;"	v
c_x	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    c_x = cam_w \/ 2$/;"	v
c_y	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    c_y = cam_h \/ 2$/;"	v
cam_h	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    cam_h = image.shape[0]$/;"	v
cam_h	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^cam_h = int(video_capture.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))$/;"	v
cam_w	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    cam_w = image.shape[1]$/;"	v
cam_w	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^cam_w = int(video_capture.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))$/;"	v
camera_distortion	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    camera_distortion = np.float32([0.0, 0.0, 0.0, 0.0, 0.0])$/;"	v
camera_matrix	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    camera_matrix = np.float32([[f_x, 0.0, c_x],$/;"	v
ckpt	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^ckpt = tf.train.get_checkpoint_state(".\/dnn_1600i_4h_3o")$/;"	v
cnt	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^cnt = my_mask_analyser.returnMaxAreaContour(image_mask)$/;"	v
coin	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^        coin = np.random.uniform()$/;"	v
comparison_array	examples/ex_color_classification_images/ex_color_classification_image.py	/^comparison_array = my_classifier.returnHistogramComparisonArray(image, method="intersection")$/;"	v
comparison_distribution	examples/ex_color_classification_images/ex_color_classification_image.py	/^comparison_distribution = comparison_array \/ np.sum(comparison_array)$/;"	v
cpt_measurement_accuracy	examples/ex_bayes_filter.py	/^cpt_measurement_accuracy = np.array([[0.6, 0.2, 0.1, 0.1, 0, 0, 0, 0, 0, 0],$/;"	v
cpt_motion_model	examples/ex_bayes_filter.py	/^cpt_motion_model = np.array([[0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0.1],$/;"	v
createPatterns	examples/ex_cnn_cascade_training_face_detection/extract_faces.py	/^def createPatterns(line, count, im, combinations, out_dir):$/;"	f
create_csv	examples/ex_dnn_head_pose_estimation_training/ex_prima_parser.py	/^def create_csv(input_path, output_path, img_size=64, colour=True, normalisation=False):$/;"	f
create_loo_pickle	examples/ex_dnn_head_pose_estimation_training/ex_prima_parser.py	/^def create_loo_pickle(csv_path, output_path, shuffle=False):$/;"	f
cut_10	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^cut_10 = (row - cut_80)\/2 #split the remaining 20%$/;"	v
cut_80	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^cut_80 = int(row * 0.8) #take 80% of the total$/;"	v
data	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^data = numpy.append(dataset, label, axis=1)$/;"	v
dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    dataset = numpy.zeros((dataset_row, dataset_col), dtype=numpy.int8)$/;"	v
dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^dataset = data[:,0:1600]$/;"	v
dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^dataset = dataset_int.astype(dtype=numpy.float32)$/;"	v
dataset_col	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    dataset_col = 64 * 64 #the size of the image$/;"	v
dataset_image_path	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^dataset_image_path = "..\/tugraz_dataset\/aflw\/data\/output\/"$/;"	v
dataset_int	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^dataset_int = numpy.load("dataset.npy")$/;"	v
dataset_npy_path	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^dataset_npy_path = "dataset.npy"$/;"	v
dataset_row	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    dataset_row = label_row$/;"	v
description	setup.py	/^  description='Head pose and Gaze estimation with Convolutional Neural Networks',$/;"	v
diff_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    diff_mask = cv2.merge([diff_mask, diff_mask, diff_mask])$/;"	v
diff_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    diff_mask = my_diff_detector.returnMask(frame)$/;"	v
drawMaxAreaCircle	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def drawMaxAreaCircle(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaCircle	deepgaze/mask_analysis.py	/^    def drawMaxAreaCircle(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaContour	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def drawMaxAreaContour(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaContour	deepgaze/mask_analysis.py	/^    def drawMaxAreaContour(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaConvexHull	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def drawMaxAreaConvexHull(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaConvexHull	deepgaze/mask_analysis.py	/^    def drawMaxAreaConvexHull(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaRectangle	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def drawMaxAreaRectangle(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawMaxAreaRectangle	deepgaze/mask_analysis.py	/^    def drawMaxAreaRectangle(self, frame, mask, color=[0,255,0], thickness=3):$/;"	m	class:BinaryMaskAnalyser
drawParticles	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
drawParticles	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
drawParticles	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
drawParticles	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
drawParticles	deepgaze/motion_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
drawParticles	deepgaze/object3d_tracking.py	/^    def drawParticles(self, frame, color=[0,0,255], radius=2):$/;"	m	class:ParticleFilter
draw_circle	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^def draw_circle(event,x,y,flags,param):$/;"	f
estimate	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
estimate	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
estimate	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
estimate	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
estimate	deepgaze/motion_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
estimate	deepgaze/object3d_tracking.py	/^    def estimate(self):$/;"	m	class:ParticleFilter
extractFaces	examples/ex_cnn_cascade_training_face_detection/extract_faces.py	/^def extractFaces(in_dir, out_dir, bb_file, patterns=False):$/;"	f
f	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^  f = open(pickle_file, 'wb')$/;"	v
f_x	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    f_x = c_x \/ np.tan(60\/2 * np.pi \/ 180)$/;"	v
f_y	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    f_y = f_x$/;"	v
faceLandmarkDetection	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^class faceLandmarkDetection:$/;"	c
faceLandmarkDetection	deepgaze/face_landmark_detection.py	/^class faceLandmarkDetection:$/;"	c
face_x1	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^    face_x1 = int(element[0])$/;"	v
face_x2	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^    face_x2 = int(face_x1+element[2])$/;"	v
face_y1	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^    face_y1 = int(element[1])$/;"	v
face_y2	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^    face_y2 = int(face_y1+element[3])$/;"	v
feed_dict	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    feed_dict = {tf_input : image_normalised}$/;"	v
feed_dict	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}$/;"	v
figManager	examples/ex_color_classification_images/ex_color_classification_image.py	/^figManager = plt.get_current_fig_manager()$/;"	v
file_name	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    file_name = str(i) + ".jpg"$/;"	v
file_name	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^    file_name = str(i) + ".jpg"$/;"	v
file_name	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch.py	/^    file_name = str(i) + ".jpg"$/;"	v
file_name	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_roll.py	/^    file_name = str(i) + ".jpg"$/;"	v
file_save	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    file_save = str(i) + "_axes.jpg"$/;"	v
final_test	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^def final_test(predictions, labels):$/;"	f
findFace	build/lib.linux-x86_64-2.7/deepgaze/haar_cascade.py	/^    def findFace(self, inputImg, $/;"	m	class:haarCascade
findFace	deepgaze/haar_cascade.py	/^    def findFace(self, inputImg, $/;"	m	class:haarCascade
font_size	examples/ex_color_classification_images/ex_color_classification_image.py	/^font_size = 20$/;"	v
fourcc	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^fourcc = cv2.cv.CV_FOURCC(*'XVID')$/;"	v
fourcc	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^fourcc = cv2.cv.CV_FOURCC(*'XVID')$/;"	v
fourcc	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^fourcc = cv2.VideoWriter_fourcc(*'XVID')$/;"	v
frame_mask	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^    frame_mask = my_motion_detector.returnMask(frame)$/;"	v
frame_mask	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^    frame_mask = my_back_detector.returnMask(frame, morph_opening=True, blur=True, kernel_size=5, iterations=2)$/;"	v
frame_mask	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^    frame_mask = my_back_detector.returnMask(frame, morph_opening=True, blur=True, kernel_size=5, iterations=2)$/;"	v
getBackground	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def getBackground(self):$/;"	m	class:DiffMotionDetector
getBackground	deepgaze/motion_detection.py	/^    def getBackground(self):$/;"	m	class:DiffMotionDetector
getRange	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def getRange(self):$/;"	m	class:RangeColorDetector
getRange	deepgaze/color_detection.py	/^    def getRange(self):$/;"	m	class:RangeColorDetector
getTemplate	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def getTemplate(self):$/;"	m	class:BackProjectionColorDetector
getTemplate	deepgaze/color_detection.py	/^    def getTemplate(self):$/;"	m	class:BackProjectionColorDetector
getTemplateList	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def getTemplateList(self):$/;"	m	class:MultiBackProjectionColorDetector
getTemplateList	deepgaze/color_detection.py	/^    def getTemplateList(self):$/;"	m	class:MultiBackProjectionColorDetector
get_entropy	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def get_entropy(self):$/;"	m	class:ParticleFilter
get_entropy	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def get_entropy(self):$/;"	m	class:ParticleFilter
get_entropy	deepgaze/motion_tracking.py	/^    def get_entropy(self):$/;"	m	class:ParticleFilter
get_entropy	deepgaze/object3d_tracking.py	/^    def get_entropy(self):$/;"	m	class:ParticleFilter
get_entropy_sample	deepgaze/object3d_tracking.py	/^    def get_entropy_sample(self, x, y):$/;"	m	class:ParticleFilter
global_step	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    global_step = tf.Variable(0)  # count the number of steps taken.$/;"	v
graph	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^graph = tf.Graph()$/;"	v
graph	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^graph = tf.Graph()$/;"	v
haarCascade	build/lib.linux-x86_64-2.7/deepgaze/haar_cascade.py	/^class haarCascade:$/;"	c
haarCascade	deepgaze/haar_cascade.py	/^class haarCascade:$/;"	c
height	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^height = 512$/;"	v
hfd	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^hfd = HaarFaceDetector("..\/..\/etc\/xml\/haarcascade_frontalface_alt.xml", "..\/..\/etc\/xml\/haarcascade_profileface.xml")$/;"	v
histogram_intersection	examples/ex_color_classification_images/ex_histogram_intersection.py	/^def histogram_intersection(hist_1, hist_2):$/;"	f
image	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    image = cv2.imread(file_name)$/;"	v
image	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^    image = cv2.imread(file_name) #Read the image with OpenCV$/;"	v
image	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch.py	/^    image = cv2.imread(file_name) #Read the image with OpenCV$/;"	v
image	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch_yaw.py	/^image = cv2.imread("1.jpg") #Read the image with OpenCV$/;"	v
image	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_roll.py	/^    image = cv2.imread(file_name) #Read the image with OpenCV$/;"	v
image	examples/ex_color_classification_images/ex_color_classification_image.py	/^image = cv2.imread('image_2.jpg') #Load the image$/;"	v
image	examples/ex_color_detection_image/ex_color_detection_image.py	/^image = cv2.imread('tiger.jpg') #Load the image$/;"	v
image	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^        image = cv2.imread(image_path, 0) #load in greyscale$/;"	v
image	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^image = cv2.imread("image.jpg", 0) $/;"	v
image	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^image = cv2.imread("tomb_rider_2.jpg") #Read the image with OpenCV$/;"	v
image	examples/ex_haar_face_detection/ex_haar_face_detection.py	/^image = cv2.imread(".\/group.jpg",0)$/;"	v
image	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^image = cv2.imread("tomb_rider.jpg") #Read the image with OpenCV$/;"	v
image	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^image = cv2.imread("tomb_rider_2.jpg") #Read the image with OpenCV$/;"	v
image	examples/ex_skin_detection_images/to_remove.py	/^image = cv2.imread("tomb_rider.jpg") #Read the image with OpenCV$/;"	v
image_canvas	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^image_canvas = np.copy(image)$/;"	v
image_filtered	examples/ex_color_detection_image/ex_color_detection_image.py	/^image_filtered = my_back_detector.returnFiltered(image, morph_opening=True, blur=True, kernel_size=7, iterations=2)$/;"	v
image_filtered	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^image_filtered = my_skin_detector.returnFiltered(image, morph_opening=True, blur=True, kernel_size=3, iterations=1)$/;"	v
image_filtered	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^image_filtered = my_skin_detector.returnFiltered(image, morph_opening=False, blur=False, kernel_size=3, iterations=1)$/;"	v
image_filtered	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^image_filtered = my_skin_detector.returnFiltered(image, morph_opening=True, blur=True, kernel_size=3, iterations=1)$/;"	v
image_filtered	examples/ex_skin_detection_images/to_remove.py	/^image_filtered = my_skin_detector.returnFiltered(image, morph_opening=False, blur=False)$/;"	v
image_list	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    image_list = list()$/;"	v
image_mask	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^image_mask = my_skin_detector.returnMask(image, morph_opening=True, blur=True, kernel_size=3, iterations=1) $/;"	v
image_normalised	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    image_normalised = np.add(image_resized, -127) #normalisation of the input$/;"	v
image_path	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^        image_path = dataset_image_path + image_name$/;"	v
image_resized	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    image_resized = cv2.resize(image, (64, 64), interpolation = cv2.INTER_AREA)$/;"	v
image_size	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    image_size = 64$/;"	v
image_size	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    image_size = 64$/;"	v
image_stack	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^image_stack = np.hstack((image, image_filtered, image_canvas))$/;"	v
image_stack	examples/ex_skin_detection_images/to_remove.py	/^image_stack = np.hstack((image, image_filtered))$/;"	v
images_stack	examples/ex_color_detection_image/ex_color_detection_image.py	/^images_stack = np.hstack((image,image_filtered)) #The images are stack in order$/;"	v
img	examples/ex_color_detection_image/ex_color_detection_image_multi.py	/^img = cv2.imread('tiger.jpg')$/;"	v
img	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^img = np.zeros((height,width,3), np.uint8)$/;"	v
img_filtered	examples/ex_color_detection_image/ex_color_detection_image_multi.py	/^img_filtered = my_back_detector.returnFiltered(img, $/;"	v
include_package_data	setup.py	/^  include_package_data=True,$/;"	v
initialise	build/lib.linux-x86_64-2.7/deepgaze/bayes_filter.py	/^    def initialise(self, prior, cpt):$/;"	m	class:DiscreteBayesFilter
initialise	deepgaze/bayes_filter.py	/^    def initialise(self, prior, cpt):$/;"	m	class:DiscreteBayesFilter
intersection	examples/ex_cnn_cascade_training_face_detection/iou.py	/^def intersection(box1, box2):$/;"	f
is_first_frame	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^is_first_frame = True$/;"	v
label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    label = numpy.genfromtxt(label_csv_path, delimiter=',', skip_header=0, usecols=(range(1,4)), dtype=numpy.float32)$/;"	v
label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^label = data[:,1600:1603]$/;"	v
label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^label = numpy.load("label.npy")$/;"	v
label_csv_path	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^label_csv_path = "..\/tugraz_dataset\/aflw\/data\/label.csv"$/;"	v
label_npy_path	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^label_npy_path = "label.npy"$/;"	v
label_objects	examples/ex_color_classification_images/ex_color_classification_image.py	/^label_objects = ('Flash', 'Batman', 'Hulk', 'Superman', 'Capt. America', 'Wonder Woman', 'Iron Man', 'Wolverine')$/;"	v
learning_rate	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    learning_rate = 0.001$/;"	v
license	setup.py	/^  license="The MIT License (MIT)",$/;"	v
load_pitch_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def load_pitch_variables(self, pitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
load_pitch_variables	deepgaze/head_pose_estimation.py	/^    def load_pitch_variables(self, pitchFilePath):$/;"	m	class:CnnHeadPoseEstimator
load_roll_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def load_roll_variables(self, rollFilePath):$/;"	m	class:CnnHeadPoseEstimator
load_roll_variables	deepgaze/head_pose_estimation.py	/^    def load_roll_variables(self, rollFilePath):$/;"	m	class:CnnHeadPoseEstimator
load_yaw_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def load_yaw_variables(self, YawFilePath):$/;"	m	class:CnnHeadPoseEstimator
load_yaw_variables	deepgaze/head_pose_estimation.py	/^    def load_yaw_variables(self, YawFilePath):$/;"	m	class:CnnHeadPoseEstimator
loss	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    loss = tf.reduce_mean(tf.square(train_prediction - tf_train_labels))$/;"	v
main	examples/ex_cnn_cascade_training_face_detection/12net_calibration_training.py	/^def main():            $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/12net_detection_training.py	/^def main():            $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/24net_calibration_training.py	/^def main():  $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/24net_detection_training.py	/^def main():  $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/48net_calibration_training.py	/^def main():            $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/48net_detection_training.py	/^def main():            $/;"	f
main	examples/ex_cnn_cascade_training_face_detection/extract_faces.py	/^def main():$/;"	f
main	examples/ex_cnn_cascade_training_face_detection/extract_neg.py	/^def main():$/;"	f
main	examples/ex_cnn_cascade_training_face_detection/iou.py	/^def main():$/;"	f
main	examples/ex_cnn_cascade_training_face_detection/nms.py	/^def main():$/;"	f
main	examples/ex_cnn_cascade_training_face_detection/preprocess_negative.py	/^def main():$/;"	f
main	examples/ex_cnn_cascade_training_face_detection/preprocess_positive.py	/^def main():$/;"	f
main	examples/ex_color_classification_images/ex_histogram_intersection.py	/^def main():$/;"	f
main	examples/ex_dlib_pnp_head_pose_estimation_video.py	/^def main():$/;"	f
main	examples/ex_dnn_head_pose_estimation_training/ex_prima_parser.py	/^def main():$/;"	f
main	examples/ex_fasa_saliency_map/ex_fasa_saliency_map_images.py	/^def main():$/;"	f
main	examples/ex_fasa_saliency_map/ex_fasa_saliency_map_webcam.py	/^def main():$/;"	f
main	examples/ex_pnp_head_pose_estimation_video.py	/^def main():$/;"	f
main	examples/ex_pnp_head_pose_estimation_webcam.py	/^def main():$/;"	f
makeSquare	examples/ex_cnn_cascade_training_face_detection/extract_faces.py	/^def makeSquare(x, y, w, h):$/;"	f
matchMaxAreaWithShape	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def matchMaxAreaWithShape(self, mask, shape):$/;"	m	class:BinaryMaskAnalyser
matchMaxAreaWithShape	deepgaze/mask_analysis.py	/^    def matchMaxAreaWithShape(self, mask, shape):$/;"	m	class:BinaryMaskAnalyser
max_pitch	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^max_pitch = numpy.amax(label[:,1])$/;"	v
max_range	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^max_range = np.array([30, 255, 255], dtype = "uint8") #upper HSV boundary of skin color$/;"	v
max_range	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^max_range = np.array([20, 150, 255], dtype = "uint8") #upper HSV boundary of skin color$/;"	v
max_range	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^max_range = np.array([30, 255, 255], dtype = "uint8") #upper HSV boundary of skin color$/;"	v
max_range	examples/ex_skin_detection_images/to_remove.py	/^max_range = np.array([30, 255, 255], dtype = "uint8") #upper HSV boundary of skin color$/;"	v
max_roll	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^max_roll = numpy.amax(label[:,0])$/;"	v
max_yaw	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^max_yaw = numpy.amax(label[:,2])$/;"	v
mean_pitch	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^mean_pitch = numpy.mean(label[:,1])$/;"	v
mean_roll	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^mean_roll = numpy.mean(label[:,0])$/;"	v
mean_yaw	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^mean_yaw = numpy.mean(label[:,2])$/;"	v
min_pitch	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^min_pitch = numpy.amin(label[:,1])$/;"	v
min_range	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^min_range = np.array([0, 58, 50], dtype = "uint8") #lower HSV boundary of skin color$/;"	v
min_range	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^min_range = np.array([0, 48, 70], dtype = "uint8") #lower HSV boundary of skin color$/;"	v
min_range	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^min_range = np.array([0, 58, 50], dtype = "uint8") #lower HSV boundary of skin color$/;"	v
min_range	examples/ex_skin_detection_images/to_remove.py	/^min_range = np.array([0, 58, 50], dtype = "uint8") #lower HSV boundary of skin color$/;"	v
min_roll	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^min_roll = numpy.amin(label[:,0])$/;"	v
min_yaw	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^min_yaw = numpy.amin(label[:,2])$/;"	v
model	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._init_yaw_
model	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^        def model(data, _dropout=1.0):$/;"	f	function:CnnHeadPoseEstimator._init_pitch_
model	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_pitch_variables
model	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_roll_variables
model	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_yaw_variables
model	deepgaze/cnn_head_pose_estimator.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._init_yaw_
model	deepgaze/cnn_head_pose_estimator.py	/^        def model(data, _dropout=1.0):$/;"	f	function:CnnHeadPoseEstimator._init_pitch_
model	deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_pitch_variables
model	deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_roll_variables
model	deepgaze/head_pose_estimation.py	/^        def model(data):$/;"	f	function:CnnHeadPoseEstimator._allocate_yaw_variables
model	examples/ex_cnn_cascade_training_face_detection/12net_calibration_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model	examples/ex_cnn_cascade_training_face_detection/12net_detection_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model	examples/ex_cnn_cascade_training_face_detection/24net_calibration_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model	examples/ex_cnn_cascade_training_face_detection/24net_detection_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model	examples/ex_cnn_cascade_training_face_detection/48net_calibration_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model	examples/ex_cnn_cascade_training_face_detection/48net_detection_training.py	/^            def model(data, _dropout=1.0):$/;"	f	function:main
model_1	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_1 = cv2.imread('model_1.png') #Flash$/;"	v
model_2	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_2 = cv2.imread('model_2.png') #Batman$/;"	v
model_3	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_3 = cv2.imread('model_3.png') #Hulk$/;"	v
model_4	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_4 = cv2.imread('model_4.png') #Superman$/;"	v
model_5	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_5 = cv2.imread('model_5.png') #Capt. America$/;"	v
model_6	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_6 = cv2.imread('model_6.png') #Wonder Woman$/;"	v
model_7	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_7 = cv2.imread('model_7.png') #Iron Man$/;"	v
model_8	examples/ex_color_classification_images/ex_color_classification_image.py	/^model_8 = cv2.imread('model_8.png') #Wolverine$/;"	v
mog2_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    mog2_mask = cv2.merge([mog2_mask, mog2_mask, mog2_mask])$/;"	v
mog2_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    mog2_mask = my_mog2_detector.returnGreyscaleMask(frame)$/;"	v
mog_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    mog_mask = cv2.merge([mog_mask, mog_mask, mog_mask])$/;"	v
mog_mask	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^    mog_mask = my_mog_detector.returnMask(frame)$/;"	v
multilayer_model	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^def multilayer_model(_X, _input0, _biases_input0, _hidden1, _biases_hidden1, _hidden2, _biases_hidden2, _output3, _biases_output3):$/;"	f
multilayer_model	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^def multilayer_model(_X, _input0, _biases_input0, _hidden1, _biases_hidden1, _hidden2, _biases_hidden2, _output3, _biases_output3):   $/;"	f
my_back_detector	examples/ex_color_detection_image/ex_color_detection_image.py	/^my_back_detector = BackProjectionColorDetector()#Defining the deepgaze color detector object$/;"	v
my_back_detector	examples/ex_color_detection_image/ex_color_detection_image_multi.py	/^my_back_detector = MultiBackProjectionColorDetector()$/;"	v
my_back_detector	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^my_back_detector = MultiBackProjectionColorDetector()$/;"	v
my_back_detector	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^my_back_detector = BackProjectionColorDetector()$/;"	v
my_classifier	examples/ex_color_classification_images/ex_color_classification_image.py	/^my_classifier = HistogramColorClassifier(channels=[0, 1, 2], hist_size=[128, 128, 128], hist_range=[0, 256, 0, 256, 0, 256], hist_type='BGR')$/;"	v
my_diff_detector	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^my_diff_detector = DiffMotionDetector()$/;"	v
my_filter	examples/ex_bayes_filter.py	/^my_filter = DiscreteBayesFilter(10)$/;"	v
my_head_pose_estimator	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^my_head_pose_estimator = CnnHeadPoseEstimator(sess) #Head pose estimation object$/;"	v
my_head_pose_estimator	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^my_head_pose_estimator = CnnHeadPoseEstimator(sess) #Head pose estimation object$/;"	v
my_head_pose_estimator	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch.py	/^my_head_pose_estimator = CnnHeadPoseEstimator(sess) #Head pose estimation object$/;"	v
my_head_pose_estimator	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch_yaw.py	/^my_head_pose_estimator = CnnHeadPoseEstimator(sess) #Head pose estimation object$/;"	v
my_head_pose_estimator	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_roll.py	/^my_head_pose_estimator = CnnHeadPoseEstimator(sess) #Head pose estimation object$/;"	v
my_mask_analyser	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^my_mask_analyser = BinaryMaskAnalyser()$/;"	v
my_mask_analyser	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^my_mask_analyser = BinaryMaskAnalyser()$/;"	v
my_mask_analyser	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^my_mask_analyser = BinaryMaskAnalyser()$/;"	v
my_mask_analyser	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^my_mask_analyser = BinaryMaskAnalyser()$/;"	v
my_mog2_detector	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^my_mog2_detector = Mog2MotionDetector()$/;"	v
my_mog_detector	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^my_mog_detector = MogMotionDetector()$/;"	v
my_motion_detector	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^my_motion_detector = DiffMotionDetector()$/;"	v
my_particle	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^my_particle = ParticleFilter(height, width, tot_particles)$/;"	v
my_particle	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^my_particle = ParticleFilter(1920, 1080, tot_particles)$/;"	v
my_skin_detector	examples/ex_face_center_color_detection/ex_face_center_color_detection.py	/^my_skin_detector = RangeColorDetector(min_range, max_range) #Define the detector object$/;"	v
my_skin_detector	examples/ex_skin_detection_images/ex_skin_detection_images.py	/^my_skin_detector = RangeColorDetector(min_range, max_range) #Define the detector object$/;"	v
my_skin_detector	examples/ex_skin_detection_images/to_remove.py	/^my_skin_detector = RangeColorDetector(min_range, max_range) #Define the detector object$/;"	v
n_patches	examples/ex_cnn_cascade_training_face_detection/extract_neg.py	/^n_patches = 40$/;"	v
noise_probability	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^noise_probability = 0.15 #in range [0, 1.0]$/;"	v
num_hidden_units_1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    num_hidden_units_1 = 256 $/;"	v
num_hidden_units_1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    num_hidden_units_1 = 256 $/;"	v
num_hidden_units_2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    num_hidden_units_2 = 256 $/;"	v
num_hidden_units_2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    num_hidden_units_2 = 256 $/;"	v
num_hidden_units_3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    num_hidden_units_3 = 256 $/;"	v
num_hidden_units_3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    num_hidden_units_3 = 256 $/;"	v
num_labels	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    num_labels = 3$/;"	v
num_labels	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    num_labels = 3$/;"	v
num_steps	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^num_steps = 50001$/;"	v
offset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    offset = (step * batch_size) % (training_label.shape[0] - batch_size)$/;"	v
offset	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^offset = int(cam_h \/ 7)$/;"	v
optimizer	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step) $/;"	v
out	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^out = cv2.VideoWriter(".\/cars_deepgaze.avi", fourcc, 20.0, (1920,1080))$/;"	v
out	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^out = cv2.VideoWriter(".\/cars_original.avi", fourcc, 20.0, (1920,1080))$/;"	v
out	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^out = cv2.VideoWriter(".\/cows_output.avi", fourcc, 25.0, (1920,1080))$/;"	v
out_diff	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^out_diff = cv2.VideoWriter(".\/cars_diff.avi", fourcc, 20.0, (1920,1080))$/;"	v
out_mog	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^out_mog = cv2.VideoWriter(".\/cars_mog.avi", fourcc, 20.0, (1920,1080))$/;"	v
out_mog2	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^out_mog2 = cv2.VideoWriter(".\/cars_mog2.avi", fourcc, 20.0, (1920,1080))$/;"	v
p_start	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    p_start = (int(c_x), int(c_y))$/;"	v
p_stop	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    p_stop = (int(imgpts[2][0][0]), int(imgpts[2][0][1]))$/;"	v
package_data	setup.py	/^  package_data={'deepgaze': ['Readme.md']},$/;"	v
packages	setup.py	/^  packages = ['deepgaze'],$/;"	v
patch_size	examples/ex_cnn_cascade_training_face_detection/extract_neg.py	/^patch_size = 48$/;"	v
pickle_file	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^pickle_file = 'aflw_dataset.pickle'$/;"	v
pickle_file	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^pickle_file = 'aflw_dataset.pickle'$/;"	v
pitch	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    pitch = my_head_pose_estimator.return_pitch(image, radians=True)  # Evaluate the pitch angle using a CNN$/;"	v
pitch	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^    pitch = my_head_pose_estimator.return_pitch(image)  # Evaluate the pitch angle using a CNN$/;"	v
pitch	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch.py	/^    pitch = my_head_pose_estimator.return_pitch(image) #Evaluate the pitch angle using a CNN$/;"	v
pitch	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch_yaw.py	/^pitch = my_head_pose_estimator.return_pitch(image) #Evaluate the pitch angle using a CNN$/;"	v
pitch_degree	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    pitch_degree = my_head_pose_estimator.return_pitch(image, radians=False)  # Evaluate the pitch angle using a CNN$/;"	v
predict	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict	build/lib.linux-x86_64-2.7/deepgaze/bayes_filter.py	/^    def predict(self, belief, cpt_motion_model):$/;"	m	class:DiscreteBayesFilter
predict	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict	deepgaze/bayes_filter.py	/^    def predict(self, belief, cpt_motion_model):$/;"	m	class:DiscreteBayesFilter
predict	deepgaze/motion_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict	deepgaze/object3d_tracking.py	/^    def predict(self, x_velocity, y_velocity, std ):$/;"	m	class:ParticleFilter
predict_context	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def predict_context(self,context_category,std ):$/;"	m	class:ParticleFilter
predict_context	deepgaze/object3d_tracking.py	/^    def predict_context(self,context_category,std ):$/;"	m	class:ParticleFilter
prediction	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    prediction = multilayer_model(tf_train_dataset, $/;"	v
predictions	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    predictions = _sess.run([prediction], feed_dict=feed_dict)$/;"	v
print_allocated_variables	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def print_allocated_variables(self):$/;"	m	class:CnnHeadPoseEstimator
print_allocated_variables	deepgaze/head_pose_estimation.py	/^    def print_allocated_variables(self):$/;"	m	class:CnnHeadPoseEstimator
reader	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^        reader = csv.reader(csvfile)$/;"	v
removeModelHistogramByName	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def removeModelHistogramByName(self, name):$/;"	m	class:HistogramColorClassifier
removeModelHistogramByName	deepgaze/color_classification.py	/^    def removeModelHistogramByName(self, name):$/;"	m	class:HistogramColorClassifier
requires	setup.py	/^  requires = ['numpy', 'cv', 'cv2', 'tensorflow']$/;"	v
resample	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
resample	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
resample	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
resample	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
resample	deepgaze/motion_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
resample	deepgaze/object3d_tracking.py	/^    def resample(self, method='residual'):$/;"	m	class:ParticleFilter
returnBestMatchIndex	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnBestMatchIndex(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnBestMatchIndex	deepgaze/color_classification.py	/^    def returnBestMatchIndex(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnBestMatchName	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnBestMatchName(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnBestMatchName	deepgaze/color_classification.py	/^    def returnBestMatchName(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnFacePosition	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def returnFacePosition(self, inputImg, $/;"	m	class:HaarFaceDetector
returnFacePosition	deepgaze/face_detection.py	/^    def returnFacePosition(self, inputImg, $/;"	m	class:HaarFaceDetector
returnFiltered	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:BackProjectionColorDetector
returnFiltered	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:MultiBackProjectionColorDetector
returnFiltered	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:RangeColorDetector
returnFiltered	deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:BackProjectionColorDetector
returnFiltered	deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:MultiBackProjectionColorDetector
returnFiltered	deepgaze/color_detection.py	/^    def returnFiltered(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:RangeColorDetector
returnGreyscaleMask	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def returnGreyscaleMask(self, foreground_image):$/;"	m	class:Mog2MotionDetector
returnGreyscaleMask	deepgaze/motion_detection.py	/^    def returnGreyscaleMask(self, foreground_image):$/;"	m	class:Mog2MotionDetector
returnHistogramComparison	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnHistogramComparison(self, hist_1, hist_2, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnHistogramComparison	deepgaze/color_classification.py	/^    def returnHistogramComparison(self, hist_1, hist_2, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnHistogramComparisonArray	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnHistogramComparisonArray(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnHistogramComparisonArray	deepgaze/color_classification.py	/^    def returnHistogramComparisonArray(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnHistogramComparisonProbability	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnHistogramComparisonProbability(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnHistogramComparisonProbability	deepgaze/color_classification.py	/^    def returnHistogramComparisonProbability(self, image, method='intersection'):$/;"	m	class:HistogramColorClassifier
returnLandmarks	build/lib.linux-x86_64-2.7/deepgaze/face_landmark_detection.py	/^    def returnLandmarks(self, inputImg, roiX, roiY, roiW, roiH, points_to_return=range(0,68)):$/;"	m	class:faceLandmarkDetection
returnLandmarks	deepgaze/face_landmark_detection.py	/^    def returnLandmarks(self, inputImg, roiX, roiY, roiW, roiH, points_to_return=range(0,68)):$/;"	m	class:faceLandmarkDetection
returnMask	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:BackProjectionColorDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:MultiBackProjectionColorDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:RangeColorDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image):$/;"	m	class:Mog2MotionDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image):$/;"	m	class:MogMotionDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image, threshold=25):$/;"	m	class:DiffMotionDetector
returnMask	build/lib.linux-x86_64-2.7/deepgaze/saliency_map.py	/^    def returnMask(self, image, tot_bins=8, format='BGR2LAB'):$/;"	m	class:FasaSaliencyMapping
returnMask	deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:BackProjectionColorDetector
returnMask	deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:MultiBackProjectionColorDetector
returnMask	deepgaze/color_detection.py	/^    def returnMask(self, frame, morph_opening=True, blur=True, kernel_size=5, iterations=1):$/;"	m	class:RangeColorDetector
returnMask	deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image):$/;"	m	class:Mog2MotionDetector
returnMask	deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image):$/;"	m	class:MogMotionDetector
returnMask	deepgaze/motion_detection.py	/^    def returnMask(self, foreground_image, threshold=25):$/;"	m	class:DiffMotionDetector
returnMask	deepgaze/saliency_map.py	/^    def returnMask(self, image, tot_bins=8, format='BGR2LAB'):$/;"	m	class:FasaSaliencyMapping
returnMaxAreaCenter	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnMaxAreaCenter(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaCenter	deepgaze/mask_analysis.py	/^    def returnMaxAreaCenter(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaCircle	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnMaxAreaCircle(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaCircle	deepgaze/mask_analysis.py	/^    def returnMaxAreaCircle(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaContour	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnMaxAreaContour(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaContour	deepgaze/mask_analysis.py	/^    def returnMaxAreaContour(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaConvexHull	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnMaxAreaConvexHull(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaConvexHull	deepgaze/mask_analysis.py	/^    def returnMaxAreaConvexHull(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaRectangle	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnMaxAreaRectangle(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMaxAreaRectangle	deepgaze/mask_analysis.py	/^    def returnMaxAreaRectangle(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnMultipleFacesPosition	build/lib.linux-x86_64-2.7/deepgaze/face_detection.py	/^    def returnMultipleFacesPosition(self, inputImg,$/;"	m	class:HaarFaceDetector
returnMultipleFacesPosition	deepgaze/face_detection.py	/^    def returnMultipleFacesPosition(self, inputImg,$/;"	m	class:HaarFaceDetector
returnNameList	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnNameList(self):$/;"	m	class:HistogramColorClassifier
returnNameList	deepgaze/color_classification.py	/^    def returnNameList(self):$/;"	m	class:HistogramColorClassifier
returnNumberOfContours	build/lib.linux-x86_64-2.7/deepgaze/mask_analysis.py	/^    def returnNumberOfContours(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnNumberOfContours	deepgaze/mask_analysis.py	/^    def returnNumberOfContours(self, mask):$/;"	m	class:BinaryMaskAnalyser
returnParticlesContribution	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesContribution	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesContribution	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesContribution	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesContribution	deepgaze/motion_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesContribution	deepgaze/object3d_tracking.py	/^    def returnParticlesContribution(self):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	deepgaze/motion_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnParticlesCoordinates	deepgaze/object3d_tracking.py	/^    def returnParticlesCoordinates(self, index=-1):$/;"	m	class:ParticleFilter
returnSize	build/lib.linux-x86_64-2.7/deepgaze/color_classification.py	/^    def returnSize(self):$/;"	m	class:HistogramColorClassifier
returnSize	deepgaze/color_classification.py	/^    def returnSize(self):$/;"	m	class:HistogramColorClassifier
return_pitch	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def return_pitch(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_pitch	deepgaze/head_pose_estimation.py	/^    def return_pitch(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_pitch_probability	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^    def return_pitch_probability(self, image):$/;"	m	class:CnnHeadPoseEstimator
return_pitch_probability	deepgaze/cnn_head_pose_estimator.py	/^    def return_pitch_probability(self, image):$/;"	m	class:CnnHeadPoseEstimator
return_roll	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def return_roll(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_roll	deepgaze/head_pose_estimation.py	/^    def return_roll(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_roll_pitch_yaw	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def return_roll_pitch_yaw(self, image, radians=False):$/;"	m	class:PnpHeadPoseEstimator
return_roll_pitch_yaw	deepgaze/head_pose_estimation.py	/^    def return_roll_pitch_yaw(self, image, radians=False):$/;"	m	class:PnpHeadPoseEstimator
return_yaw	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def return_yaw(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_yaw	deepgaze/head_pose_estimation.py	/^    def return_yaw(self, image, radians=False):$/;"	m	class:CnnHeadPoseEstimator
return_yaw_probability	build/lib.linux-x86_64-2.7/deepgaze/cnn_head_pose_estimator.py	/^    def return_yaw_probability(self, image):$/;"	m	class:CnnHeadPoseEstimator
return_yaw_probability	deepgaze/cnn_head_pose_estimator.py	/^    def return_yaw_probability(self, image):$/;"	m	class:CnnHeadPoseEstimator
roll	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    roll = my_head_pose_estimator.return_roll(image, radians=True)  # Evaluate the roll angle using a CNN$/;"	v
roll	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^    roll = my_head_pose_estimator.return_roll(image)  # Evaluate the roll angle using a CNN$/;"	v
roll	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_roll.py	/^    roll = my_head_pose_estimator.return_roll(image) #Evaluate the roll angle using a CNN$/;"	v
roll_degree	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    roll_degree = my_head_pose_estimator.return_roll(image, radians=False)  # Evaluate the roll angle using a CNN$/;"	v
rot_matrix	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    rot_matrix = yaw2rotmat(-yaw[0,0,0]) #Deepgaze use different convention for the Yaw, we have to use the minus sign$/;"	v
rotationMatrixToEulerAngles	build/lib.linux-x86_64-2.7/deepgaze/head_pose_estimation.py	/^    def rotationMatrixToEulerAngles(self, R) :$/;"	m	class:PnpHeadPoseEstimator
rotationMatrixToEulerAngles	deepgaze/head_pose_estimation.py	/^    def rotationMatrixToEulerAngles(self, R) :$/;"	m	class:PnpHeadPoseEstimator
row_counter	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^    row_counter = 0$/;"	v
save	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^  save = {$/;"	v
save	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  save = pickle.load(f)$/;"	v
saver	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    saver = tf.train.Saver({'dnn_weights_input0': weights_input0, $/;"	v
sess	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^sess = tf.Session() #Launch the graph in a session.$/;"	v
sess	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^sess = tf.Session() #Launch the graph in a session.$/;"	v
sess	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch.py	/^sess = tf.Session() #Launch the graph in a session.$/;"	v
sess	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch_yaw.py	/^sess = tf.Session() #Launch the graph in a session.$/;"	v
sess	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_roll.py	/^sess = tf.Session() #Launch the graph in a session.$/;"	v
setBackground	build/lib.linux-x86_64-2.7/deepgaze/motion_detection.py	/^    def setBackground(self, frame):$/;"	m	class:DiffMotionDetector
setBackground	deepgaze/motion_detection.py	/^    def setBackground(self, frame):$/;"	m	class:DiffMotionDetector
setRange	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def setRange(self, min_range, max_range):$/;"	m	class:RangeColorDetector
setRange	deepgaze/color_detection.py	/^    def setRange(self, min_range, max_range):$/;"	m	class:RangeColorDetector
setTemplate	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def setTemplate(self, frame):$/;"	m	class:BackProjectionColorDetector
setTemplate	deepgaze/color_detection.py	/^    def setTemplate(self, frame):$/;"	m	class:BackProjectionColorDetector
setTemplateList	build/lib.linux-x86_64-2.7/deepgaze/color_detection.py	/^    def setTemplateList(self, frame_list):$/;"	m	class:MultiBackProjectionColorDetector
setTemplateList	deepgaze/color_detection.py	/^    def setTemplateList(self, frame_list):$/;"	m	class:MultiBackProjectionColorDetector
show_pickle_element	examples/ex_dnn_head_pose_estimation_training/ex_prima_parser.py	/^def show_pickle_element(pickle_file, element, element_type="training", img_size=64):$/;"	f
std	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^std = 25 $/;"	v
std	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^std = 25 $/;"	v
std_pitch	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^std_pitch = numpy.std(label[:,1])$/;"	v
std_roll	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^std_roll = numpy.std(label[:,0])$/;"	v
std_yaw	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^std_yaw = numpy.std(label[:,2])$/;"	v
template	examples/ex_color_detection_image/ex_color_detection_image.py	/^template = image[225:275,625:675] #Taking a subframe of the image$/;"	v
template	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^template = cv2.imread('template.png') #Load the image$/;"	v
template_list	examples/ex_color_detection_image/ex_color_detection_image_multi.py	/^template_list=list()$/;"	v
template_list	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^template_list=list()$/;"	v
test_dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^test_dataset = numpy.copy(dataset[cut_80+cut_10:row,:])$/;"	v
test_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  test_dataset = save['test_dataset']$/;"	v
test_label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^test_label = numpy.copy(label[cut_80+cut_10:row,:])$/;"	v
test_label	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  test_label = save['test_label']$/;"	v
test_prediction	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    test_prediction = multilayer_model(tf_test_dataset, $/;"	v
tf_input	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    tf_input = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))$/;"	v
tf_test_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    tf_test_dataset = tf.constant(test_dataset)$/;"	v
tf_train_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))$/;"	v
tf_train_labels	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))$/;"	v
tf_valid_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    tf_valid_dataset = tf.constant(validation_dataset)$/;"	v
tot_particles	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^tot_particles = 100$/;"	v
tot_particles	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^tot_particles = 3000$/;"	v
total_objects	examples/ex_color_classification_images/ex_color_classification_image.py	/^total_objects = 8$/;"	v
train_prediction	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    train_prediction = multilayer_model(tf_train_dataset, $/;"	v
training_dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^training_dataset = numpy.copy(dataset[0:cut_80,:]) $/;"	v
training_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  training_dataset = save['training_dataset']$/;"	v
training_label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^training_label = numpy.copy(label[0:cut_80,:]) $/;"	v
training_label	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  training_label = save['training_label']$/;"	v
tvec	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    tvec = np.array([0.0, 0.0, 1.0], np.float) # translation vector$/;"	v
ui	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^ui = UInput()$/;"	v
update	build/lib.linux-x86_64-2.7/deepgaze/3d_object_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update	build/lib.linux-x86_64-2.7/deepgaze/3dobject_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update	build/lib.linux-x86_64-2.7/deepgaze/bayes_filter.py	/^    def update(self, belief_predicted, measure, cpt_measure_accuracy):$/;"	m	class:DiscreteBayesFilter
update	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update	build/lib.linux-x86_64-2.7/deepgaze/object3d_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update	deepgaze/bayes_filter.py	/^    def update(self, belief_predicted, measure, cpt_measure_accuracy):$/;"	m	class:DiscreteBayesFilter
update	deepgaze/motion_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update	deepgaze/object3d_tracking.py	/^    def update(self, x, y):$/;"	m	class:ParticleFilter
update_normal	build/lib.linux-x86_64-2.7/deepgaze/motion_tracking.py	/^    def update_normal(self, x, y):$/;"	m	class:ParticleFilter
update_normal	deepgaze/motion_tracking.py	/^    def update_normal(self, x, y):$/;"	m	class:ParticleFilter
url	setup.py	/^  url='https:\/\/github.com\/mpatacchiola\/deepgaze',$/;"	v
valid_prediction	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    valid_prediction = multilayer_model(tf_valid_dataset, $/;"	v
validation_dataset	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^validation_dataset = numpy.copy(dataset[cut_80:cut_80+cut_10,:])$/;"	v
validation_dataset	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  validation_dataset = save['validation_dataset']$/;"	v
validation_label	examples/ex_dnn_head_pose_estimation_training/ex_aflw_parser.py	/^validation_label = numpy.copy(label[cut_80:cut_80+cut_10,:])$/;"	v
validation_label	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^  validation_label = save['validation_label']$/;"	v
version	setup.py	/^  version='0.1',$/;"	v
video_capture	examples/ex_diff_motion_detection_video/ex_diff_motion_detection.py	/^video_capture = cv2.VideoCapture(".\/cars.avi")$/;"	v
video_capture	examples/ex_motion_detectors_comparison_video/ex_motion_detectors_comparison_video.py	/^video_capture = cv2.VideoCapture(".\/cars.avi")$/;"	v
video_capture	examples/ex_multi_backprojection_hand_tracking_gaming/ex_multi_backprojection_hand_tracking_gaming.py	/^video_capture=cv2.VideoCapture(0) #Open the webcam$/;"	v
video_capture	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^    video_capture = cv2.VideoCapture(".\/cows.avi")$/;"	v
video_capture	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^    video_capture = cv2.VideoCapture(0) #Open the webcam$/;"	v
weights_hidden1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    weights_hidden1 = tf.Variable(tf.truncated_normal([num_hidden_units_1, num_hidden_units_2], 0.0, 1.0))$/;"	v
weights_hidden1	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    weights_hidden1 = tf.Variable(tf.truncated_normal([num_hidden_units_1, num_hidden_units_2], 0.0, 1.0))$/;"	v
weights_hidden2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    weights_hidden2 = tf.Variable(tf.truncated_normal([num_hidden_units_2, num_hidden_units_3], 0.0, 1.0)) $/;"	v
weights_hidden2	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    weights_hidden2 = tf.Variable(tf.truncated_normal([num_hidden_units_2, num_hidden_units_3], 0.0, 1.0)$/;"	v
weights_input0	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    weights_input0 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_units_1], 0.0, 1.0))    $/;"	v
weights_input0	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    weights_input0 = tf.Variable(tf.truncated_normal([image_size * image_size, num_hidden_units_1], 0.0, 1.0))    $/;"	v
weights_output3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_testing.py	/^    weights_output3 = tf.Variable(tf.truncated_normal([num_hidden_units_3, num_labels], 0.0, 1.0))    $/;"	v
weights_output3	examples/ex_dnn_head_pose_estimation_training/ex_dnn_head_pose_estimation_training.py	/^    weights_output3 = tf.Variable(tf.truncated_normal([num_hidden_units_3, num_labels], 0.0, 1.0))    $/;"	v
width	examples/ex_color_classification_images/ex_color_classification_image.py	/^width = 0.5 $/;"	v
width	examples/ex_particle_filter_mouse_tracking/ex_particle_filter_mouse_tracking.py	/^width = 800$/;"	v
x_noise	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^            x_noise = 0$/;"	v
x_noise	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^            x_noise = int(np.random.uniform(-300, 300))$/;"	v
y_noise	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^            y_noise = 0$/;"	v
y_noise	examples/ex_particle_filter_object_tracking_video/ex_particle_filter_object_tracking_video.py	/^            y_noise = int(np.random.uniform(-300, 300))$/;"	v
yaw	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    yaw = my_head_pose_estimator.return_yaw(image, radians=True)  # Evaluate the yaw angle using a CNN$/;"	v
yaw	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images.py	/^    yaw = my_head_pose_estimator.return_yaw(image)  # Evaluate the yaw angle using a CNN$/;"	v
yaw	examples/ex_cnn_head_pose_estimation_images/ex_cnn_head_pose_estimation_images_pitch_yaw.py	/^yaw = my_head_pose_estimator.return_yaw(image) #Evaluate the yaw angle using a CNN$/;"	v
yaw2rotmat	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^def yaw2rotmat(yaw):$/;"	f
yaw_degree	examples/ex_cnn_head_pose_axes/ex_cnn_head_pose_estimation_axes.py	/^    yaw_degree = my_head_pose_estimator.return_yaw(image, radians=False)  # Evaluate the yaw angle using a CNN$/;"	v
